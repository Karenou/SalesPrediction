{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy import savetxt, save, load\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "#code=utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def mean_absolute_percent_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # avoid devide by 0\n",
    "    y_true = y_true + 0.1\n",
    "    return round(np.mean(np.abs((y_true - y_pred) / y_true)), 2)\n",
    "\n",
    "def eval_metrics(y_test, y_pred):\n",
    "    rmse = round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)), 2)\n",
    "    mape = mean_absolute_percent_error(y_test, y_pred)\n",
    "    return rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(qty):\n",
    "    data = qty.rolling(window = 28).mean().dropna()\n",
    "    # consider one-week replenishment\n",
    "    data = data.iloc[:-7]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 74236\n",
      "0.0 61401\n",
      "0.0 78702\n",
      "0.0 71906\n",
      "0.0 72741\n",
      "0.0 64446\n",
      "0.0 78657\n",
      "0.0 19827\n",
      "0.0 72801\n",
      "0.0 14314\n",
      "0.0 78127\n",
      "0.0 20310\n",
      "0.0 75026\n",
      "0.0 71496\n",
      "0.0 78882\n",
      "0.0 60046\n",
      "0.0 80442\n",
      "0.0 78262\n",
      "0.0 77837\n",
      "0.0 74156\n",
      "0.0 79112\n",
      "0.0 2829\n",
      "0.0 78412\n",
      "0.0 74861\n",
      "0.0 79802\n",
      "0.0 78142\n",
      "0.0 77897\n",
      "0.0 77982\n",
      "0.0 81387\n",
      "0.0 78372\n",
      "0.0 4236\n",
      "0.0 80517\n",
      "0.0 76371\n",
      "0.0 78012\n",
      "0.0 79347\n",
      "0.0 78867\n",
      "0.0 78192\n",
      "0.0 76161\n",
      "0.0 50401\n",
      "0.0 70706\n",
      "0.0 71946\n",
      "0.0 76441\n",
      "0.0 80207\n",
      "0.0 76156\n",
      "0.0 77867\n",
      "0.0 77011\n",
      "0.0 77291\n",
      "0.0 74121\n",
      "0.0 77521\n",
      "0.0 76301\n",
      "0.0 72786\n",
      "0.0 79227\n",
      "0.0 77036\n",
      "0.0 77682\n",
      "0.0 60041\n",
      "0.0 76836\n",
      "0.0 72011\n",
      "0.0 10356\n",
      "0.0 78042\n",
      "0.0 16558\n",
      "0.0 71891\n",
      "0.0 72766\n",
      "0.0 74246\n",
      "0.0 71991\n",
      "0.0 61396\n",
      "0.0 73896\n",
      "0.0 76826\n",
      "0.0 79962\n",
      "0.0 74966\n",
      "0.0 74566\n",
      "0.0 76181\n",
      "0.0 72821\n",
      "0.0 78932\n",
      "0.0 78707\n",
      "0.0 74706\n",
      "0.0 76261\n",
      "0.0 19843\n",
      "0.0 74496\n",
      "0.0 65031\n",
      "0.0 78557\n",
      "0.0 80357\n",
      "0.0 77296\n",
      "0.0 76536\n",
      "0.0 74116\n",
      "0.0 21937\n",
      "0.0 78497\n",
      "0.0 79692\n",
      "0.0 74166\n",
      "0.0 78182\n",
      "0.0 23123\n",
      "0.0 77241\n",
      "0.0 9939\n",
      "0.0 74681\n",
      "0.0 74811\n",
      "0.0 78752\n",
      "0.0 72736\n",
      "0.0 80212\n",
      "0.0 72061\n",
      "0.0 77086\n",
      "0.0 78022\n",
      "0.0 77176\n",
      "0.0 79687\n",
      "0.0 78767\n",
      "0.0 3172\n",
      "0.0 74141\n",
      "0.0 76151\n",
      "0.0 76191\n",
      "0.0 76211\n",
      "0.0 79417\n",
      "0.0 74776\n",
      "0.0 76801\n",
      "0.0 80567\n",
      "0.0 78887\n",
      "0.0 20293\n",
      "0.0 76996\n",
      "0.0 76136\n",
      "0.0 78597\n",
      "0.0 81152\n",
      "0.0 72826\n",
      "0.0 74856\n",
      "0.0 74221\n",
      "0.0 74151\n",
      "0.0 77972\n",
      "0.0 71911\n",
      "0.0 14835\n",
      "0.0 71986\n",
      "0.0 72816\n",
      "0.0 4094\n",
      "0.0 79732\n",
      "0.0 79727\n",
      "0.0 77511\n",
      "0.0 79792\n",
      "0.0 81392\n",
      "0.0 76931\n",
      "0.0 79717\n",
      "0.0 76216\n",
      "0.0 79827\n",
      "0.0 76796\n",
      "0.0 74821\n",
      "0.0 49386\n",
      "0.0 78732\n",
      "0.0 79377\n",
      "0.0 80217\n",
      "0.0 76141\n",
      "0.0 79362\n",
      "0.0 77702\n",
      "0.0 9685\n",
      "0.0 76446\n",
      "0.0 40223\n",
      "0.0 79887\n",
      "0.0 78232\n",
      "0.0 76436\n",
      "0.0 74136\n",
      "0.0 78672\n",
      "0.0 80487\n",
      "0.0 79392\n",
      "0.0 77221\n",
      "0.0 21083\n",
      "0.0 8976\n",
      "0.0 65831\n",
      "0.0 80222\n",
      "0.0 78982\n",
      "0.0 73891\n",
      "0.0 77832\n",
      "0.0 73621\n",
      "0.0 4235\n",
      "0.0 76221\n",
      "0.0 80247\n",
      "0.0 78772\n",
      "0.0 77161\n",
      "0.0 78827\n",
      "0.0 78562\n",
      "0.0 74171\n",
      "0.0 78747\n",
      "0.0 11815\n",
      "0.0 77056\n",
      "0.0 74786\n",
      "0.0 76701\n",
      "0.0 74256\n",
      "0.0 63996\n",
      "0.0 74556\n",
      "0.0 74321\n",
      "0.0 6299\n",
      "0.0 15386\n",
      "0.0 78542\n",
      "0.0 77081\n",
      "0.0 72041\n",
      "0.0 72796\n",
      "0.0 79952\n",
      "0.0 78002\n",
      "0.0 74131\n",
      "0.0 4092\n",
      "0.0 78877\n",
      "0.0 9943\n",
      "0.0 77251\n",
      "0.0 76806\n",
      "0.0 80502\n",
      "0.0 64876\n",
      "0.0 71951\n",
      "0.0 77531\n",
      "0.0 74591\n",
      "0.0 78132\n",
      "0.0 79777\n",
      "0.0 59161\n",
      "0.0 79117\n",
      "0.0 77621\n",
      "0.0 78822\n",
      "0.0 78652\n",
      "0.0 74731\n",
      "0.0 71876\n",
      "0.0 72006\n",
      "0.0 9046\n",
      "0.0 9944\n",
      "0.0 7324\n",
      "0.0 71136\n",
      "0.0 72021\n",
      "0.0 6995\n",
      "0.0 77962\n",
      "0.0 78457\n",
      "0.0 72121\n",
      "0.0 79397\n",
      "0.0 78487\n",
      "0.0 78897\n",
      "0.0 79822\n",
      "0.0 77146\n",
      "0.0 77051\n",
      "0.0 23047\n",
      "0.0 76861\n",
      "0.0 72771\n",
      "0.0 56876\n",
      "0.0 77021\n",
      "0.0 78027\n",
      "0.0 79857\n",
      "0.0 74146\n",
      "0.0 77156\n",
      "0.0 72131\n",
      "0.0 73266\n",
      "0.0 74686\n",
      "0.0 49391\n",
      "0.0 73586\n",
      "0.0 61476\n",
      "0.0 79582\n",
      "0.0 79972\n",
      "0.0 79192\n",
      "0.0 79607\n",
      "0.0 74841\n",
      "0.0 77006\n",
      "0.0 78367\n",
      "0.0 72991\n",
      "0.0 78432\n",
      "0.0 71866\n",
      "0.0 71916\n",
      "0.0 20294\n",
      "0.0 72836\n",
      "0.0 73591\n",
      "0.0 71751\n",
      "0.0 76146\n",
      "0.0 81242\n",
      "0.0 83332\n",
      "0.0 78092\n",
      "0.0 73511\n",
      "0.0 4093\n",
      "0.0 71981\n",
      "0.0 78357\n",
      "0.0 74501\n",
      "0.0 72966\n",
      "0.0 9941\n",
      "0.0 19828\n",
      "0.0 77091\n",
      "0.0 77481\n",
      "0.0 74126\n",
      "0.0 72791\n",
      "0.0 78647\n",
      "0.0 77687\n",
      "0.0 77031\n",
      "0.0 77126\n",
      "0.0 76236\n",
      "0.0 77491\n",
      "0.0 76176\n",
      "0.0 78162\n",
      "0.0 76911\n",
      "0.0 20162\n",
      "0.0 76841\n",
      "0.0 72811\n",
      "0.0 74241\n",
      "0.0 6948\n",
      "0.0 8993\n",
      "0.0 9940\n",
      "0.0 74266\n",
      "0.0 77902\n",
      "0.0 74161\n",
      "0.0 77236\n",
      "0.0 72016\n",
      "0.0 1119\n",
      "0.0 79772\n",
      "0.0 70811\n",
      "0.0 81092\n",
      "0.0 6085\n",
      "0.0 79932\n",
      "0.0 78902\n",
      "0.0 79292\n",
      "0.0 78097\n",
      "0.0 78737\n",
      "0.0 80242\n",
      "0.0 77977\n",
      "0.0 72781\n",
      "0.0 74711\n",
      "0.0 78637\n",
      "0.0 72696\n",
      "0.0 13253\n",
      "0.0 78007\n",
      "0.0 79282\n",
      "0.0 74871\n",
      "0.0 74851\n",
      "0.0 70571\n",
      "0.0 77321\n",
      "0.0 78962\n",
      "0.0 71881\n",
      "0.0 72721\n",
      "0.0 76866\n",
      "0.0 77947\n",
      "0.0 77862\n",
      "0.0 78302\n",
      "0.0 78617\n",
      "0.0 74771\n",
      "0.0 78057\n",
      "0.0 76186\n",
      "0.0 77206\n",
      "0.0 79492\n",
      "0.0 78112\n",
      "0.0 72761\n",
      "0.0 81247\n",
      "0.0 74766\n",
      "0.0 77076\n",
      "0.0 79737\n",
      "0.0 77116\n",
      "0.0 74831\n",
      "0.0 77822\n",
      "0.0 78642\n",
      "0.0 78777\n",
      "0.0 78157\n",
      "0.0 77466\n",
      "0.0 72841\n",
      "0.0 64901\n",
      "0.0 72046\n",
      "0.0 76226\n",
      "0.0 71871\n",
      "0.0 77016\n",
      "0.0 78857\n",
      "0.0 78522\n",
      "0.0 74546\n",
      "0.0 74881\n",
      "0.0 79102\n",
      "0.0 76846\n",
      "0.0 74836\n",
      "0.0 74746\n",
      "0.0 78862\n",
      "0.0 29192\n",
      "0.0 44197\n",
      "0.0 83357\n",
      "0.0 77632\n",
      "0.0 74736\n",
      "0.0 8686\n",
      "0.0 76821\n",
      "0.0 3171\n",
      "0.0 78792\n",
      "0.0 71996\n",
      "0.0 77191\n",
      "0.0 14834\n",
      "0.0 74826\n",
      "0.0 77026\n",
      "0.0 77872\n",
      "0.0 78377\n",
      "0.0 74326\n",
      "0.0 1887\n",
      "0.0 76851\n",
      "0.0 79782\n",
      "0.0 78537\n",
      "0.0 77201\n",
      "0.0 71901\n",
      "0.0 78742\n",
      "0.0 83322\n",
      "0.0 78122\n",
      "0.0 9683\n",
      "0.0 77096\n",
      "0.0 74756\n",
      "0.0 77071\n",
      "0.0 76231\n",
      "0.0 76131\n",
      "0.0 9942\n",
      "0.0 76201\n",
      "0.0 78892\n",
      "0.0 79202\n",
      "0.0 79712\n",
      "0.0 80957\n",
      "0.0 74751\n",
      "0.0 22501\n",
      "0.0 61416\n",
      "0.0 68041\n",
      "0.0 77061\n",
      "0.0 76816\n",
      "0.0 72116\n",
      "0.0 76811\n",
      "0.0 77246\n",
      "0.0 78677\n",
      "0.0 65906\n",
      "0.0 74816\n",
      "0.0 71886\n",
      "0.0 78872\n",
      "0.0 78362\n",
      "0.0 22508\n",
      "0.0 78967\n",
      "0.0 76171\n",
      "0.0 69621\n",
      "0.0 77882\n",
      "0.0 77932\n",
      "0.0 73506\n",
      "0.0 78062\n",
      "0.0 76831\n",
      "0.0 72746\n",
      "0.0 72831\n",
      "0.0 72616\n",
      "0.0 81257\n",
      "0.0 76856\n",
      "0.0 79842\n",
      "0.0 78087\n",
      "0.0 9253\n",
      "0.0 77486\n",
      "0.0 4237\n",
      "0.0 79877\n",
      "0.0 78972\n",
      "0.0 80082\n",
      "0.0 74761\n",
      "0.0 77041\n",
      "0.0 71921\n",
      "0.0 79247\n",
      "0.0 72001\n",
      "0.0 76241\n",
      "0.0 78847\n",
      "0.0 78662\n",
      "0.0 20295\n",
      "0.0 32788\n",
      "0.0 79702\n",
      "0.0 74846\n",
      "0.0 74866\n",
      "0.0 78217\n",
      "0.0 72031\n",
      "0.0 77566\n",
      "0.0 78782\n",
      "0.0 72126\n",
      "0.0 76921\n",
      "0.0 78427\n",
      "0.0 76256\n",
      "0.0 77892\n",
      "0.0 71976\n",
      "0.0 20314\n",
      "0.0 72036\n",
      "0.0 72056\n",
      "0.0 76686\n",
      "0.0 78757\n",
      "0.0 77912\n",
      "0.0 32798\n",
      "0.0 74876\n",
      "0.0 78147\n",
      "0.0 76731\n",
      "0.0 77166\n",
      "0.0 80577\n",
      "0.0 76951\n",
      "0.0 78787\n",
      "0.0 78442\n",
      "0.0 78037\n",
      "0.0 77171\n",
      "0.0 78312\n",
      "0.0 79947\n",
      "0.0 76166\n",
      "0.0 78722\n",
      "0.0 77216\n",
      "0.0 78107\n",
      "0.0 74696\n",
      "0.0 8708\n",
      "2.0 78922\n",
      "2.0 77652\n",
      "2.0 75806\n",
      "2.0 79577\n",
      "2.0 75791\n",
      "2.0 79287\n",
      "2.0 79697\n",
      "2.0 78067\n",
      "2.0 77571\n",
      "2.0 77151\n",
      "2.0 78482\n",
      "2.0 75671\n",
      "2.0 75811\n",
      "2.0 78137\n",
      "2.0 78607\n",
      "2.0 18121\n",
      "2.0 78927\n",
      "2.0 78387\n",
      "2.0 79342\n",
      "2.0 63946\n",
      "2.0 78712\n",
      "2.0 79897\n",
      "2.0 9044\n",
      "2.0 63171\n",
      "2.0 75861\n",
      "2.0 75691\n",
      "2.0 80472\n",
      "2.0 75976\n",
      "2.0 74806\n",
      "2.0 79762\n",
      "2.0 78937\n",
      "2.0 78952\n",
      "2.0 76986\n",
      "2.0 64746\n",
      "2.0 71231\n",
      "2.0 42138\n",
      "2.0 79572\n",
      "2.0 79322\n",
      "2.0 79352\n",
      "2.0 76251\n",
      "2.0 75646\n",
      "2.0 68261\n",
      "2.0 77186\n",
      "2.0 79867\n",
      "2.0 6300\n",
      "2.0 76751\n",
      "2.0 77556\n",
      "2.0 74791\n",
      "2.0 79922\n",
      "2.0 79862\n",
      "2.0 47081\n",
      "2.0 19829\n",
      "2.0 80362\n",
      "2.0 78222\n",
      "2.0 79407\n",
      "2.0 75626\n",
      "2.0 24291\n",
      "2.0 80657\n",
      "2.0 78227\n",
      "2.0 82102\n",
      "2.0 75941\n",
      "2.0 72026\n",
      "2.0 71146\n",
      "2.0 75756\n",
      "2.0 75846\n",
      "2.0 78032\n",
      "2.0 75936\n",
      "2.0 75836\n",
      "2.0 4668\n",
      "2.0 79882\n",
      "2.0 76126\n",
      "2.0 79547\n",
      "2.0 79357\n",
      "2.0 69436\n",
      "2.0 78382\n",
      "2.0 77642\n",
      "2.0 78572\n",
      "2.0 79267\n",
      "2.0 74181\n",
      "2.0 75726\n",
      "2.0 77066\n",
      "2.0 80117\n",
      "2.0 72756\n",
      "2.0 66736\n",
      "2.0 78842\n",
      "2.0 79832\n",
      "2.0 74176\n",
      "2.0 77942\n",
      "2.0 76746\n",
      "2.0 79837\n",
      "2.0 82897\n",
      "2.0 74741\n",
      "2.0 78917\n",
      "2.0 75001\n",
      "2.0 78242\n",
      "2.0 20312\n",
      "2.0 77917\n",
      "2.0 76206\n",
      "2.0 75851\n",
      "2.0 78152\n",
      "2.0 79297\n",
      "2.0 71896\n",
      "2.0 74991\n",
      "2.0 75971\n",
      "2.0 78907\n",
      "2.0 80477\n",
      "2.0 79892\n",
      "2.0 79812\n",
      "2.0 75786\n",
      "2.0 79072\n",
      "2.0 74216\n",
      "2.0 79197\n",
      "2.0 79497\n",
      "2.0 78832\n",
      "2.0 77501\n",
      "2.0 79872\n",
      "2.0 44817\n",
      "2.0 81987\n",
      "2.0 79767\n",
      "2.0 22774\n",
      "2.0 79372\n",
      "2.0 80927\n",
      "2.0 77506\n",
      "2.0 78587\n",
      "2.0 79902\n",
      "2.0 76741\n",
      "2.0 79752\n",
      "2.0 77997\n",
      "2.0 76196\n",
      "2.0 37953\n",
      "2.0 76761\n",
      "2.0 72066\n",
      "2.0 77431\n",
      "2.0 78517\n",
      "2.0 75011\n",
      "2.0 73881\n",
      "2.0 78397\n",
      "2.0 78402\n",
      "2.0 23621\n",
      "2.0 79367\n",
      "2.0 79742\n",
      "2.0 77842\n",
      "2.0 77131\n",
      "2.0 79852\n",
      "2.0 79327\n",
      "2.0 73596\n",
      "2.0 78837\n",
      "2.0 79272\n",
      "2.0 73886\n",
      "2.0 83337\n",
      "2.0 80237\n",
      "2.0 77952\n",
      "2.0 74781\n",
      "2.0 77181\n",
      "2.0 61406\n",
      "2.0 72071\n",
      "2.0 76246\n",
      "2.0 72051\n",
      "2.0 76736\n",
      "2.0 77196\n",
      "2.0 78727\n",
      "2.0 79847\n",
      "2.0 78957\n",
      "2.0 79707\n",
      "2.0 79977\n",
      "2.0 71656\n",
      "2.0 19820\n",
      "2.0 77046\n",
      "2.0 79337\n",
      "2.0 80347\n",
      "2.0 20673\n",
      "2.0 79077\n",
      "2.0 76706\n",
      "2.0 80232\n",
      "2.0 81142\n",
      "2.0 80717\n",
      "3.0 80557\n",
      "Model             Group    Num_Products    RMSE    MAPE\n",
      "--------------  -------  --------------  ------  ------\n",
      "Moving Average        0            5092    1.02    2.88\n",
      "Moving Average        1               0   -0      -0\n",
      "Moving Average        2             955    1.44    3.2\n",
      "Moving Average        3             184   30.88   33.34\n"
     ]
    }
   ],
   "source": [
    "timestep = 1\n",
    "\n",
    "import json\n",
    "with open(\"../data/all/group_ids.json\") as json_file:\n",
    "    group_ids = json.load(json_file)\n",
    "\n",
    "with open(\"../data/all/group_product_ids.json\") as json_file:\n",
    "    group_product_ids = json.load(json_file)\n",
    "\n",
    "rmse, mape, X_train, X_test, Y_train, Y_test = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "for index, group_id in enumerate(group_ids):\n",
    "    Y_train[group_id] = pd.read_json('../data/all/boosting_input_data/group%d_Y_train.json' % (group_id), orient='split')\n",
    "    Y_test[group_id] = pd.read_json('../data/all/boosting_input_data/group%d_Y_test.json' % (group_id), orient = 'split')\n",
    "    \n",
    "    n = len(group_product_ids[str(group_id)])\n",
    "    skip = 1\n",
    "    ncols = 2\n",
    "    nrows = int(n / ncols)\n",
    "    selected_product = random.sample(group_product_ids[str(group_id)], n)\n",
    "    _rmse, _mape = 0, 0\n",
    "#     fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(20,10))\n",
    "#     plt.subplots_adjust(wspace=0.1)\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            product_id = selected_product[ncols*i+j]\n",
    "            y_train, y_test = Y_train[group_id], Y_test[group_id]\n",
    "            y_train.product_id = y_train.product_id.apply(np.int64)\n",
    "            y_test.product_id = y_test.product_id.apply(np.int64)\n",
    "            y_test = y_test[y_test.product_id == product_id].qty\n",
    "            y_train = y_train[y_train.product_id == product_id].qty\n",
    "            qty = pd.concat([y_train, y_test], axis = 0, ignore_index=True)\n",
    "            if len(qty) < 60:\n",
    "                skip += 1\n",
    "                continue\n",
    "            y_pred = moving_average(qty)\n",
    "            # compare prediction accuracy, train: test = 70: 30\n",
    "            test_size = int(len(y_pred) * 0.3)\n",
    "            y_pred = y_pred.iloc[-test_size:].reset_index(drop=True)\n",
    "            qty = qty.iloc[-test_size:].reset_index(drop=True)\n",
    "#             ax[i][j].plot(qty, linewidth = 1, label = 'Actual sales qty', color = 'blue', linestyle = 'dashed')\n",
    "#             ax[i][j].plot(y_pred, linewidth = 1, label = 'Predict sales qty', color = 'red')\n",
    "#             title = 'Qty for group %d, product %d, rmse: %f, mape: %f' % (int(group_id), product_id, \n",
    "#                                                                      round(eval_metrics(qty, y_pred)[0], 2), \n",
    "#                                                                      round(eval_metrics(qty, y_pred)[1],2))\n",
    "#             ax[i][j].set_title(title)\n",
    "            _rmse += eval_metrics(qty, y_pred)[0]\n",
    "            _mape += eval_metrics(qty, y_pred)[1]\n",
    "#     plt.show()\n",
    "    with open(\"../data/all/group_product_ids.json\", \"w\") as outfile:\n",
    "        json.dump(group_product_ids, outfile)\n",
    "    rmse[group_id], mape[group_id] = round(_rmse / (n-skip), 2), round(_mape / (n-skip), 2)\n",
    "\n",
    "Model = 'Moving Average'\n",
    "table = [[Model, 0, len(group_product_ids[str(0.0)]), rmse[0], mape[0]],\n",
    "         [Model, 1, len(group_product_ids[str(1.0)]), rmse[1], mape[1]],\n",
    "         [Model, 2, len(group_product_ids[str(2.0)]), rmse[2], mape[2]],\n",
    "         [Model, 3, len(group_product_ids[str(3.0)]), rmse[3], mape[3]]]\n",
    "\n",
    "print(tabulate(table, headers=[\"Model\",\"Group\", \"Num_Products\", \"RMSE\", \"MAPE\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
